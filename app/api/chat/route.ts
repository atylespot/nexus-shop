import { NextRequest, NextResponse } from 'next/server';
import { openai } from '@/lib/ai';
import { prisma } from '@/lib/db';
import { getServerSession } from 'next-auth';
import OpenAI from 'openai';

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
         const { message, sessionId, customerInfo, messageType = 'text', pageContext } = body;

    // Debug: Check environment variables
    console.log('ЁЯФН Environment Check:');
    console.log('OPENAI_API_KEY exists:', !!process.env.OPENAI_API_KEY);
    console.log('OPENAI_API_KEY length:', process.env.OPENAI_API_KEY?.length || 0);
    console.log('OPENAI_API_KEY starts with sk-:', process.env.OPENAI_API_KEY?.startsWith('sk-') || false);

    if (!message) {
      return NextResponse.json({ error: 'Message is required' }, { status: 400 });
    }

    // Create or get chat session
    let chatSession = await prisma.chatSession.findUnique({
      where: { sessionId },
      include: { messages: { orderBy: { createdAt: 'asc' } } }
    });

    if (!chatSession) {
      chatSession = await prisma.chatSession.create({
        data: {
          sessionId: sessionId || `session_${Date.now()}`,
          customerName: customerInfo?.name,
          customerPhone: customerInfo?.phone,
          customerEmail: customerInfo?.email,
          metadata: customerInfo || {}
        },
        include: { messages: { orderBy: { createdAt: 'asc' } } }
      });
    }

    // Save customer message
    await prisma.chatMessage.create({
      data: {
        sessionId: chatSession.id,
        content: message,
        messageType,
        senderType: 'customer',
        senderName: customerInfo?.name || 'Customer'
      }
    });

    // Get chat bot settings
    const botSettings = await prisma.chatBotSetting.findFirst();
    const systemPrompt = botSettings?.systemPrompt || 
      "You are a helpful AI assistant for an e-commerce website. Respond in Bengali (Bangla) language. Help customers with product information, orders, and general queries.";

    // Check if API key is configured
    if (!botSettings?.openaiApiKey) {
      return NextResponse.json({
        success: false,
        error: 'OpenAI API key not configured. Please configure it in Admin Panel тЖТ AI Chat тЖТ Settings.'
      }, { status: 400 });
    }

         // Prepare context for AI
     const context = await prepareAIContext(message, chatSession, pageContext);

    // Generate AI response
    const aiResponse = await generateAIResponse(message, context, systemPrompt, botSettings.openaiApiKey);

    // Save AI response
    await prisma.chatMessage.create({
      data: {
        sessionId: chatSession.id,
        content: aiResponse,
        messageType: 'text',
        senderType: 'ai',
        senderName: 'AI Assistant'
      }
    });

    // Update session
    await prisma.chatSession.update({
      where: { id: chatSession.id },
      data: { updatedAt: new Date() }
    });

    return NextResponse.json({
      success: true,
      response: aiResponse,
      sessionId: chatSession.sessionId
    });

  } catch (error) {
    console.error('Chat API Error:', error);
    return NextResponse.json(
      { error: 'Failed to process chat message' },
      { status: 500 }
    );
  }
}

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const sessionId = searchParams.get('sessionId');

    if (!sessionId) {
      return NextResponse.json({ error: 'Session ID is required' }, { status: 400 });
    }

    const chatSession = await prisma.chatSession.findUnique({
      where: { sessionId },
      include: { 
        messages: { 
          orderBy: { createdAt: 'asc' },
          take: 50 // Limit to last 50 messages
        } 
      }
    });

    if (!chatSession) {
      return NextResponse.json({ error: 'Session not found' }, { status: 404 });
    }

    return NextResponse.json({
      success: true,
      session: chatSession
    });

  } catch (error) {
    console.error('Chat API Error:', error);
    return NextResponse.json(
      { error: 'Failed to fetch chat session' },
      { status: 500 }
    );
  }
}

async function prepareAIContext(message: string, chatSession: any, pageContext?: string) {
  const context: any = {
    websiteInfo: {
      name: "Nexus Shop",
      type: "E-commerce",
      currency: "BDT",
      contact: {
        email: "support@nexusshop.com",
        whatsapp: "+8801234567890",
        website: "https://nexusshop.com"
      }
    },
    pageContext: pageContext || 'unknown',
    recentMessages: chatSession.messages.slice(-5).map((msg: any) => ({
      role: msg.senderType === 'customer' ? 'user' : 'assistant',
      content: msg.content
    })),
    smartGuidance: {
      productExploration: "ржЖржкржирж┐ ржЖржорж╛ржжрзЗрж░ ржУржпрж╝рзЗржмрж╕рж╛ржЗржЯрзЗ ржпрзЗ ржХрзЛржи ржкрзНрж░рзЛржбрж╛ржХрзНржЯ ржХрзНрж▓рж┐ржХ ржХрж░рзЗ ржжрзЗржЦрждрзЗ ржкрж╛рж░рзЗржиред ржЖржкржирж┐ ржХрзЛржи ржкрзНрж░рзЛржбрж╛ржХрзНржЯрзЗрж░ ржирж╛ржо ржмрж▓рзБржи, ржЖржорж┐ ржЖржкржирж╛ржХрзЗ ржмрж┐рж╕рзНрждрж╛рж░рж┐ржд рждржерзНржп ржжрж┐рждрзЗ ржкрж╛рж░ржмред",
      contactInfo: "ржЖржкржирж╛рж░ ржХрж╛ржЩрзНржХрзНрж╖рж┐ржд ржЙрждрзНрждрж░ ржирж╛ ржкрзЗрж▓рзЗ, рж╕рж░рж╛рж╕рж░рж┐ ржпрзЛржЧрж╛ржпрзЛржЧ ржХрж░рзБржи: ржЗржорзЗржЗрж▓: support@nexusshop.com, WhatsApp: +8801234567890",
      selfService: "ржЖржкржирж┐ ржЖржорж╛ржжрзЗрж░ ржУржпрж╝рзЗржмрж╕рж╛ржЗржЯрзЗ ржирж┐ржЬрзЗржЗ ржкрзНрж░рзЛржбрж╛ржХрзНржЯ ржжрзЗржЦрждрзЗ ржкрж╛рж░рзЗржи ржПржмржВ ржЖржкржирж╛рж░ ржкржЫржирзНржжрзЗрж░ ржЖржЗржЯрзЗржо ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рждрзЗ ржкрж╛рж░рзЗржиред"
    }
  };

  // Check if customer is asking for general product information (not specific)
  const isGeneralProductQuery = (
    message.toLowerCase().includes('product') || 
    message.toLowerCase().includes('price') || 
    message.toLowerCase().includes('cost') ||
    message.toLowerCase().includes('ржжрж╛ржо') ||
    message.toLowerCase().includes('ржкрзНрж░рзЛржбрж╛ржХрзНржЯ') ||
    message.toLowerCase().includes('ржХрж┐ ржХрж┐') ||
    message.toLowerCase().includes('рж╕ржм') ||
    message.toLowerCase().includes('рж▓рж┐рж╕рзНржЯ')
  ) && !message.toLowerCase().includes('specific') && !message.toLowerCase().includes('ржирж┐рж░рзНржжрж┐рж╖рзНржЯ');

  if (isGeneralProductQuery) {
    // Don't provide product list, instead guide them
    context.guidance = "general_product_query";
    context.message = "Customer is asking for general product information. Guide them to explore the website and ask for specific product names.";
  }

  // Only provide product info if customer mentions a specific product
  const specificProductMatch = message.match(/(?:ржкрзНрж░рзЛржбрж╛ржХрзНржЯ|product|item|ржЖржЗржЯрзЗржо)\s+(?:ржирж╛ржо|name)?\s*[:\-]?\s*([^\s,ред]+)/i);
  if (specificProductMatch) {
    const productName = specificProductMatch[1];
    const products = await prisma.product.findMany({
      where: {
        OR: [
          { name: { contains: productName, mode: 'insensitive' } },
          { description: { contains: productName, mode: 'insensitive' } }
        ]
      },
      take: 5,
      include: {
        category: true,
        inventory: true,
        images: { take: 1 }
      }
    });

    if (products.length > 0) {
      context.specificProducts = products.map(p => ({
        id: p.id,
        name: p.name,
        price: p.regularPrice,
        salePrice: p.salePrice,
        currency: p.currency,
        category: p.category.name,
        stock: p.inventory?.quantity || 0,
        image: p.images[0]?.url,
        description: p.description
      }));
    }
  }

  // Add order information if customer is asking about orders
  if (message.toLowerCase().includes('order') || 
      message.toLowerCase().includes('ржЕрж░рзНржбрж╛рж░') ||
      message.toLowerCase().includes('track')) {
    
    const orders = await prisma.order.findMany({
      take: 5,
      orderBy: { createdAt: 'desc' }
    });

    context.recentOrders = orders;
  }

  return context;
}

async function generateAIResponse(message: string, context: any, systemPrompt: string, apiKey: string) {
  try {
    // Check if OpenAI API key is provided
    if (!apiKey) {
      console.log('тЭМ OpenAI API key not provided');
      return 'ржжрзБржГржЦрж┐ржд, AI рж╕рж┐рж╕рзНржЯрзЗржо ржПржЦржи ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рж╛ рж╣ржпрж╝ржирж┐ред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЕрзНржпрж╛ржбржорж┐ржирзЗрж░ рж╕рж╛ржерзЗ ржпрзЛржЧрж╛ржпрзЛржЧ ржХрж░рзБржиред';
    }

    console.log('тЬЕ OpenAI API key found, proceeding with AI generation');

    // Create smart context-aware messages
    let smartPrompt = systemPrompt;
    
    // Add context-specific guidance
    if (context.guidance === "general_product_query") {
      smartPrompt += `\n\nIMPORTANT: Customer is asking for general product information. DO NOT provide product lists. Instead:
      1. Guide them to explore the website
      2. Ask them to click on products and tell you the name
      3. Provide contact information for direct queries
      4. Be helpful but encourage self-service`;
    }
    
    if (context.specificProducts && context.specificProducts.length > 0) {
      smartPrompt += `\n\nCustomer mentioned specific product(s). Provide detailed information about: ${context.specificProducts.map(p => p.name).join(', ')}`;
    }

    const messages = [
      { role: 'system', content: smartPrompt },
      ...context.recentMessages,
      { role: 'user', content: message }
    ];

    console.log('ЁЯдЦ Sending request to OpenAI with messages:', messages.length);

    // Create OpenAI client with provided API key
    const openaiClient = new OpenAI({ 
      apiKey: apiKey, 
      dangerouslyAllowBrowser: false 
    });

    const response = await openaiClient.chat.completions.create({
      model: 'gpt-4o-mini',
      messages,
      max_tokens: 1000,
      temperature: 0.7
    });

    const aiResponse = response.choices[0]?.message?.content?.trim();
    console.log('тЬЕ AI response generated successfully:', aiResponse?.substring(0, 100) + '...');

    return aiResponse || 'ржжрзБржГржЦрж┐ржд, ржЖржорж┐ ржПржЦржи ржЙрждрзНрждрж░ ржжрж┐рждрзЗ ржкрж╛рж░ржЫрж┐ ржирж╛ред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред';

  } catch (error: any) {
    console.error('OpenAI Error:', error);
    
    // Check for specific error types
    if (error.code === 'invalid_api_key' || error.status === 401) {
      console.log('тЭМ Invalid API key or unauthorized');
      return 'ржжрзБржГржЦрж┐ржд, AI рж╕рж┐рж╕рзНржЯрзЗржо ржПржЦржи ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рж╛ рж╣ржпрж╝ржирж┐ред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЕрзНржпрж╛ржбржорж┐ржирзЗрж░ рж╕рж╛ржерзЗ ржпрзЛржЧрж╛ржпрзЛржЧ ржХрж░рзБржиред';
    } else if (error.status === 429) {
      console.log('тЭМ Rate limit exceeded');
      return 'ржжрзБржГржЦрж┐ржд, AI рж╕рж┐рж╕рзНржЯрзЗржо ржПржЦржи ржмрзНржпрж╕рзНрждред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржХрж┐ржЫрзБржХрзНрж╖ржг ржкрж░ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред';
    } else if (error.status >= 500) {
      console.log('тЭМ OpenAI server error');
      return 'ржжрзБржГржЦрж┐ржд, AI рж╕рж┐рж╕рзНржЯрзЗржорзЗ ржПржХржЯрж┐ рж╕ржорж╕рзНржпрж╛ рж╣ржпрж╝рзЗржЫрзЗред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржХрж┐ржЫрзБржХрзНрж╖ржг ржкрж░ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред';
    }
    
    console.log('тЭМ Unknown error:', error.message);
    return 'ржжрзБржГржЦрж┐ржд, ржПржХржЯрж┐ рждрзНрж░рзБржЯрж┐ рж╣ржпрж╝рзЗржЫрзЗред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред';
  }
}
